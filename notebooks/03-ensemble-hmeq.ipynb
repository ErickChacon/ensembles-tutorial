{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Boosting for Classifier Decision Trees\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "options(repr.plot.width = 15, repr.plot.height = 10)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Goal\n",
                "\n",
                "In this tutorial, we will demonstrate the use of an ensemble method known as *boosting* for\n",
                "*classifier decision trees*. We will study the `HMEQ` dataset available at [https://www.kaggle.com/datasets/ajay1735/hmeq-data](https://www.kaggle.com/datasets/ajay1735/hmeq-data), which contains information about applicants who applied for home equity line of credit. It contains the following variables:\n",
                "\n",
                "* **BAD:** Target variable: 1 = default on loan, 0 = repaid;\n",
                "* **LOAN:** amount of the loan request;\n",
                "* **MORTDUE:** amount due on existing mortgage;\n",
                "* **VALUE:** value of the current property;\n",
                "* **REASON:** reason for the loan (home improvement, debt consolidation);\n",
                "* **JOB:** job category of the applicant (e.g., `Mgr`, `Office`, `Self`, `Sales`, `Other`);\n",
                "* **YOJ:** years at present job;\n",
                "* **DEROG:** number of major derogatory reports;\n",
                "* **DELINQ:** number of delinquent credit lines;\n",
                "* **CLAGE:** age of the oldest credit line (in months);\n",
                "* **NINQ:** number of recent credit inquiries;\n",
                "* **CLNO:** number of existing credit lines; and\n",
                "* **DEBTINC:** debt-to-income ratio.\n",
                "\n",
                "## Load libraries and data\n",
                "\n",
                "First, we load the required libraries. We use the `rpart` package because it contains\n",
                "implementations of decision trees, and the `adabag` package because it has implemented the\n",
                "*boosting* algorithm.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(rpart)\n",
                "library(adabag)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To load an `*.csv` file, simply use the function `read.csv()`. In addition, use `factor()`\n",
                "to convert our response variable of interest to `factor`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hmeq <- read.csv(file.path(\"data\", \"hmeq.csv\"), header = TRUE)\n",
                "hmeq$BAD <- factor(hmeq$BAD)\n",
                "head(hmeq)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploratory analysis\n",
                "\n",
                "We begin by obtaining summaries of the variables in the `hmeq` dataset.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary(hmeq)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will analyze the applicants behaviour for the line credit (`BAD`).\n",
                "\n",
                "## Prepare train, validation and test data\n",
                "\n",
                "In order to evaluate the adequacy of our models, we split the data into three groups:\n",
                "\n",
                "- **Testing data**: to fit or trian the models,\n",
                "- **Validation data**: to compare and select models,\n",
                "- **Test data**: to evaluate the final performance.\n",
                "\n",
                "Let's create the row indices associated to each split. We set a seed with `set.seed()` to\n",
                "be able to reproduce the same train-validation-test split:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "set.seed(45632)\n",
                "test_indices <- sample(1:nrow(hmeq), 800, replace = FALSE)\n",
                "remaining <- setdiff(1:nrow(hmeq), test_indices)\n",
                "valid_indices <- sample(remaining, 800, replace = FALSE)\n",
                "train_indices <- setdiff(remaining, valid_indices)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's obtain each data split:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data <- hmeq[train_indices, ]\n",
                "valid_data <- hmeq[valid_indices, ]\n",
                "test_data <- hmeq[test_indices, ]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "head(train_data)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "head(valid_data)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "head(test_data)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Classifier Decision Tree\n",
                "\n",
                "Let's start fitting a decision tree with the `rpart` package, and predict in the\n",
                "validation data using a arbitrary threshold ($0.5$) to exemplify the method:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "initial_tree <- rpart(BAD ~ ., data = train_data)\n",
                "initial_predictions <- predict(initial_tree, newdata = valid_data)\n",
                "initial_predictions <- ifelse(initial_predictions[, 2] > 0.5, 1, 0)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Print the confusion matrix of the basic model:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "initial_tree_performance <- data.frame(observed = factor(valid_data$BAD),\n",
                "                                       predicted = factor(initial_predictions))\n",
                "initial_cm <- with(initial_tree_performance, table(predicted, observed))\n",
                "initial_cm\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "initial_error <- 1 - sum(diag(initial_cm)) / sum(initial_cm)\n",
                "initial_error\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Boosting method\n",
                "\n",
                "### Train\n",
                "\n",
                "Now build the boosting model using the `boosting()` function from the `adabag` package. Be\n",
                "careful with the number of iterations (`mfinal`) because this may take a long time. The\n",
                "hyper-parameters to control the growth for the decision tree can be passed to the argument\n",
                "`control` with the function `rpart.control` with arguments:\n",
                "\n",
                "- **minsplit**: minimum number of observations in a node to attempt an split;\n",
                "- **cp**: controls the complexity parameter for the stopping rule, if negative no pruning\n",
                "  is done; and\n",
                "- **maxdepth**: the maximum depth of the argument.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "boosted_model <- boosting(BAD ~ ., data = train_data, mfinal = 100,\n",
                "                          control = rpart.control(minsplit = 5, cp = -1, maxdepth = 4))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Predict on the validation data\n",
                "\n",
                "Create predictions on the validation data, and print the confusion matrix:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "boosted_predictions <- predict.boosting(boosted_model, newdata = valid_data)\n",
                "boosted_predictions$confusion\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Print the error rate:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "boosted_predictions$error\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plot a trace of how the error evolves as the ensemble size grows.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trace <- errorevol(boosted_model, valid_data)\n",
                "plot(trace[[1]], xlab = \"Ensemble size\", ylab = \"Error rate\", type = \"b\", pch = 19)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check performance on test data\n",
                "\n",
                "Create predictions of the best model on the test data, and print the confusion matrix:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions_best_model <- predict.boosting(boosted_model, newdata = test_data)\n",
                "predictions_best_model$confusion\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Print the error rate on the test data:\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions_best_model$error\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
